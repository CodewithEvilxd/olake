version: "3"

services:
  # lakekeeper:
  #   image: &lakekeeper-image ${LAKEKEEPER__SERVER_IMAGE:-quay.io/lakekeeper/catalog:latest-main}
  #   pull_policy: &lakekeeper-pull-policy always
  #   environment: &lakekeeper-environment
  #     - LAKEKEEPER__PG_ENCRYPTION_KEY=This-is-NOT-Secure!
  #     - LAKEKEEPER__PG_DATABASE_URL_READ=postgresql://iceberg:password@postgres:5432/iceberg
  #     - LAKEKEEPER__PG_DATABASE_URL_WRITE=postgresql://iceberg:password@postgres:5432/iceberg
  #     - LAKEKEEPER__AUTHZ_BACKEND=allowall
  #     # Externally taken from environment variables if set
  #     - LAKEKEEPER__OPENID_PROVIDER_URI
  #     - LAKEKEEPER__OPENID_AUDIENCE
  #     - LAKEKEEPER__OPENID_ADDITIONAL_ISSUERS
  #     - LAKEKEEPER__UI__OPENID_CLIENT_ID
  #     - LAKEKEEPER__UI__OPENID_SCOPE
  #   command: [ "serve" ]
  #   healthcheck:
  #     test: [ "CMD", "/home/nonroot/iceberg-catalog", "healthcheck" ]
  #     interval: 1s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 3s
  #   depends_on:
  #     migrate:
  #       condition: service_completed_successfully
  #   ports:
  #     - "8181:8181"
  #   networks:
  #     iceberg_net:


  # migrate:
  #   image: *lakekeeper-image
  #   pull_policy: *lakekeeper-pull-policy
  #   environment: *lakekeeper-environment
  #   restart: "no"
  #   command: [ "migrate" ]
  #   depends_on:
  #     postgres:
  #       condition: service_healthy
  #   networks:
  #     iceberg_net:


  spark-iceberg:
    image: tabulario/spark-iceberg
    container_name: spark-iceberg
    build: spark/
    networks:
      iceberg_net:
    depends_on:
      - minio
      - postgres
    volumes:
      - ./spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
      - ./data/ivy-cache:/root/.ivy2
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    ports:
      - 8888:8888
      - 8088:8080
      - 10000:10000
      - 10001:10001

  minio:
    image: minio/minio
    container_name: minio
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
      - MINIO_DOMAIN=minio
    networks:
      iceberg_net:
        aliases:
          - warehouse.minio
    ports:
      - 9001:9001
      - 9000:9000
    volumes:
      - ./data/minio-data:/data
    command: [ "server", "/data", "--console-address", ":9001" ]

  mc:
    depends_on:
      - minio
    image: minio/mc
    container_name: mc
    networks:
      iceberg_net:
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    entrypoint: |
      /bin/sh -c "
      until (/usr/bin/mc config host add minio http://minio:9000 admin password) do echo '...waiting...' && sleep 1; done;
      if ! /usr/bin/mc ls minio/warehouse > /dev/null 2>&1; then
        /usr/bin/mc mb minio/warehouse;
        /usr/bin/mc policy set public minio/warehouse;
      fi;
      tail -f /dev/null
      "

  postgres:
    image: postgres:15
    container_name: iceberg-postgres
    networks:
      iceberg_net:
    environment:
      - POSTGRES_USER=iceberg
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=iceberg
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "iceberg", "-d", "iceberg" ]
      interval: 2s
      timeout: 10s
      retries: 3
      start_period: 10s
    ports:
      - 5432:5432
    volumes:
      - ./data/postgres-data:/var/lib/postgresql/data

  hive-metastore:
    image: apache/hive:4.0.0
    container_name: hive-metastore
    networks:
      iceberg_net:
    ports:
      - "9083:9083"
    environment:
        - SERVICE_NAME=metastore
    depends_on:
      - postgres
    user: root
    volumes:
        - ./data/ivy-cache:/opt/ivy-cache
        - ./hive-site.conf:/opt/hive/conf/hive-site.xml
    entrypoint: |
      /bin/sh -c "
      # Create ivy-cache directories
      mkdir -p /opt/ivy-cache/jars
      chmod -R 777 /opt/ivy-cache
      
      # Check if curl is available, if not try to use apt-get
      if ! command -v curl > /dev/null; then
        if command -v apt-get > /dev/null; then
          apt-get update && apt-get install -y curl
        else
          echo 'Neither curl nor apt-get is available. Cannot download dependencies.'
          exit 1
        fi
      fi
      
      # Download dependencies to ivy-cache if they don't exist
      if [ ! -f /opt/ivy-cache/jars/hadoop-aws-3.3.6.jar ]; then
        echo 'Downloading hadoop-aws-3.3.6.jar to ivy-cache...'
        curl -L -o /opt/ivy-cache/jars/hadoop-aws-3.3.6.jar https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.6/hadoop-aws-3.3.6.jar
        
        # Verify download was successful
        if [ ! -f /opt/ivy-cache/jars/hadoop-aws-3.3.6.jar ] || [ ! -s /opt/ivy-cache/jars/hadoop-aws-3.3.6.jar ]; then
          echo 'Failed to download hadoop-aws-3.3.6.jar. Exiting.'
          exit 1
        fi
      fi
      
      if [ ! -f /opt/ivy-cache/jars/aws-java-sdk-bundle-1.11.1026.jar ]; then
        echo 'Downloading aws-java-sdk-bundle-1.11.1026.jar to ivy-cache...'
        curl -L -o /opt/ivy-cache/jars/aws-java-sdk-bundle-1.11.1026.jar https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.1026/aws-java-sdk-bundle-1.11.1026.jar
        
        # Verify download was successful
        if [ ! -f /opt/ivy-cache/jars/aws-java-sdk-bundle-1.11.1026.jar ] || [ ! -s /opt/ivy-cache/jars/aws-java-sdk-bundle-1.11.1026.jar ]; then
          echo 'Failed to download aws-java-sdk-bundle-1.11.1026.jar. Exiting.'
          exit 1
        fi
      fi
      
      if [ ! -f /opt/ivy-cache/jars/postgresql-42.5.1.jar ]; then
        echo 'Downloading postgresql-42.5.1.jar to ivy-cache...'
        curl -L -o /opt/ivy-cache/jars/postgresql-42.5.1.jar https://repo1.maven.org/maven2/org/postgresql/postgresql/42.5.1/postgresql-42.5.1.jar
        
        # Verify download was successful
        if [ ! -f /opt/ivy-cache/jars/postgresql-42.5.1.jar ] || [ ! -s /opt/ivy-cache/jars/postgresql-42.5.1.jar ]; then
          echo 'Failed to download postgresql-42.5.1.jar. Exiting.'
          exit 1
        fi
      fi
      
      echo 'All dependencies downloaded to ivy-cache. Copying to Hive lib directory...'
      
      # Copy the JAR files to Hive's lib directory
      cp /opt/ivy-cache/jars/hadoop-aws-3.3.6.jar /opt/hive/lib/ || { echo 'Failed to copy hadoop-aws-3.3.6.jar'; exit 1; }
      cp /opt/ivy-cache/jars/aws-java-sdk-bundle-1.11.1026.jar /opt/hive/lib/ || { echo 'Failed to copy aws-java-sdk-bundle-1.11.1026.jar'; exit 1; }
      cp /opt/ivy-cache/jars/postgresql-42.5.1.jar /opt/hive/lib/ || { echo 'Failed to copy postgresql-42.5.1.jar'; exit 1; }
      
      # Verify files were copied successfully
      if [ ! -f /opt/hive/lib/hadoop-aws-3.3.6.jar ] || [ ! -f /opt/hive/lib/aws-java-sdk-bundle-1.11.1026.jar ] || [ ! -f /opt/hive/lib/postgresql-42.5.1.jar ]; then
        echo 'JAR files not found in Hive lib directory. Exiting.'
        exit 1
      fi
      
      # Fix permissions for Hive directories
      chown -R hive:hive /opt/hive/lib
      
      echo 'JAR files copied to Hive lib directory. Starting hive-metastore...'
      
      # Start the hive metastore service
      sh -c "/entrypoint.sh"
      "

networks:
  iceberg_net:


volumes:
  postgres-data:
  minio-data:
